{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering_1_Assgn_airlines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inamansari21/datascience/blob/main/Clustering_1_Assgn_airlines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXU68U7Kj5Gd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.cluster.hierarchy as sch\n",
        "from sklearn.cluster import AgglomerativeClustering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QvGB5hlqyZ3"
      },
      "source": [
        "data = pd.read_excel('EastWestAirlines.xlsx', sheet_name='data')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXy13-EtsVCO"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTONQyYOsgfU"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYatezQwsygp"
      },
      "source": [
        "data=data.rename({'ID#':'ID', 'Award?':'Award'} , axis=1)\n",
        "data.head()\n",
        "# Renaming columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpbXlWDAtfZF"
      },
      "source": [
        "def check_int(df):\n",
        "    count = 0\n",
        "    for row in df:\n",
        "        try:\n",
        "            if type(row) != int:\n",
        "                df.loc[count] = np.nan\n",
        "        except:\n",
        "            pass\n",
        "        count +=1\n",
        " # Checking for all the values in dataset of type integer, if not replacing them with nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0YdKGjeuGw9"
      },
      "source": [
        "check_int(data[data.columns])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjLMvDijuGtT"
      },
      "source": [
        "data.isna().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCS_HaNFuGrv"
      },
      "source": [
        "data.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju0G4TqVuGoV"
      },
      "source": [
        "data['Award'].value_counts().plot(kind='pie', autopct='%2.0f%%', fontsize='18', \n",
        "                                        colors = ['#F11A05','#43E206'], shadow =True)\n",
        "plt.show()\n",
        "# Checking previously awarded miles ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF5T27P0uGmt"
      },
      "source": [
        "# Checking relation between Balance and Days_since_enroll\n",
        "import seaborn as sns\n",
        "fig, ax =plt.subplots(figsize=(40,12))\n",
        "ax = sns.lineplot(x= 'Days_since_enroll', y='Balance',data = data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5sOAhmm2W0I"
      },
      "source": [
        " **AGLOMERATIVE CLUSTERING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J4t4vfduGjB"
      },
      "source": [
        "data1 = data.drop('ID', axis = 1)\n",
        "data1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd5wLYy1uGhR"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_BfpTa50gXW"
      },
      "source": [
        "#check clustering for two different scaling functions\n",
        "scaler1 = MinMaxScaler()\n",
        "scaler2 = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUhZYasW0qhg"
      },
      "source": [
        "# Normalizing Dataset\n",
        "scaler1_df = scaler1.fit_transform(data1)\n",
        "print(scaler1_df)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "scaler2_df = scaler2.fit_transform(data1)\n",
        "print(scaler2_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N51zfFrZ00zJ"
      },
      "source": [
        "# Create Dendrograms\n",
        "plt.figure(figsize=(10, 7))  \n",
        "dendograms=sch.dendrogram(sch.linkage(scaler1_df,'complete'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUnAkJGr09yq"
      },
      "source": [
        "plt.figure(figsize=(10, 7))  \n",
        "dendograms=sch.dendrogram(sch.linkage(scaler2_df,'complete'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7OU79gC1lWG"
      },
      "source": [
        "# Creating clusters\n",
        "H_clusters=AgglomerativeClustering(n_clusters=5,affinity='euclidean',linkage='ward')\n",
        "H_clusters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXlibjnm2vnA"
      },
      "source": [
        "# Using data normalized by MinMaxScaler \n",
        "y=pd.DataFrame(H_clusters.fit_predict(scaler1_df),columns=['clustersid'])\n",
        "y['clustersid'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYd3kjlG2vkC"
      },
      "source": [
        "# Adding clusters to dataset\n",
        "# 1. cluster id with scaler_1 i.e. minmaxscaler\n",
        "data['clustersid_s1']=H_clusters.labels_\n",
        "data\n",
        "\n",
        "data1['clustersid_s1']=H_clusters.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFw06K5s2vhW"
      },
      "source": [
        "# Plotting barplot using groupby method to get visualization of how many row no. in each cluster\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "data.groupby(['clustersid_s1']).count()['ID'].plot(kind='bar')\n",
        "plt.ylabel('ID Counts')\n",
        "plt.title('Hierarchical Clustering',fontsize='large',fontweight='bold')\n",
        "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
        "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
        "plt.yticks(fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_YQrZQ52vfu"
      },
      "source": [
        "data1.groupby('clustersid_s1').agg(['mean']).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvRCyRro2vc2"
      },
      "source": [
        "# silhouette_score of AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prB5jclR2vao"
      },
      "source": [
        "sil_score= silhouette_score(scaler1_df, H_clusters.labels_)\n",
        "sil_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkbRp23L2vXW"
      },
      "source": [
        "# Using data normalized by StandardScaler\n",
        "y=pd.DataFrame(H_clusters.fit_predict(scaler2_df),columns=['clustersid'])\n",
        "y['clustersid'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2z-K-IG2vVz"
      },
      "source": [
        "# Adding clusters to dataset\n",
        "# 1. cluster id with scaler_1 i.e. StandardScaler\n",
        "data['clustersid_s2']=H_clusters.labels_\n",
        "data1['clustersid_s2']=H_clusters.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANLX4K5W3sED"
      },
      "source": [
        "# Plotting barplot using groupby method to get visualization of how many row no. in each cluster\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "data.groupby(['clustersid_s2']).count()['ID'].plot(kind='bar')\n",
        "plt.ylabel('ID Counts')\n",
        "plt.title('Hierarchical Clustering',fontsize='large',fontweight='bold')\n",
        "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
        "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
        "plt.yticks(fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaXk9-Me3z9s"
      },
      "source": [
        "data1.groupby('clustersid_s1').agg(['mean']).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9OwjVNg343e"
      },
      "source": [
        "# silhouette_score of AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "sil_score= silhouette_score(scaler2_df, H_clusters.labels_)\n",
        "sil_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhtgOUIx4DzN"
      },
      "source": [
        "**K-MEANS CLUSTERING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na9NM_XA39YG"
      },
      "source": [
        "# Import Library\n",
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyjkEwDF4YVL"
      },
      "source": [
        "scaler1 = MinMaxScaler()\n",
        "scaler2 = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFc_Es2C4a9_"
      },
      "source": [
        "# Normalizing Dataset\n",
        "scaler1_df = scaler1.fit_transform(data1)\n",
        "print(scaler1_df)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "scaler2_df = scaler2.fit_transform(data1)\n",
        "print(scaler2_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWY_gp214qfF"
      },
      "source": [
        "# Using data normalized by MinMaxScaler\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i,random_state=0)\n",
        "    kmeans.fit(scaler1_df)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "    \n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwr3jYRB4yoW"
      },
      "source": [
        "# Using data normalized by StandardScaler\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i,random_state=0)\n",
        "    kmeans.fit(scaler2_df)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "    \n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9I_FJuH5CYB"
      },
      "source": [
        "**From above two Scree plots, optimum number of clusters can be selected equal to 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFRSUi7F43RK"
      },
      "source": [
        "#Build Cluster algorithm\n",
        "\n",
        "\n",
        "# Using data normalized by MinMaxScaler\n",
        "clusters_new1 = KMeans(5, random_state=42)\n",
        "clusters_new1.fit(scaler1_df)\n",
        "\n",
        "sil_score= silhouette_score(scaler1_df, clusters_new1.labels_)\n",
        "print('Silhouette Score for data normalized by MinMaxScaler: ',sil_score)\n",
        "\n",
        "# Using data normalized by StandardScaler\n",
        "clusters_new2 = KMeans(5, random_state=42)\n",
        "clusters_new2.fit(scaler2_df)\n",
        "\n",
        "sil_score= silhouette_score(scaler2_df, clusters_new2.labels_)\n",
        "print('Silhouette Score for data normalized by StandardScaler: ',sil_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjyY7Gtd5M8U"
      },
      "source": [
        "#Assign clusters to the data set\n",
        "data['clusterid_Kmeans'] = clusters_new1.labels_\n",
        "data1['clusterid_Kmeans'] = clusters_new1.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj0ah-oK5QyR"
      },
      "source": [
        "y=pd.DataFrame(clusters_new1.fit_predict(scaler1_df),columns=['clusterid_Kmeans'])\n",
        "y['clusterid_Kmeans'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEgCBlAb5S7e"
      },
      "source": [
        "# Plotting barplot using groupby method to get visualization of how many row no. in each cluster\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "data.groupby(['clusterid_Kmeans']).count()['ID'].plot(kind='bar')\n",
        "plt.ylabel('ID Counts')\n",
        "plt.title('Hierarchical Clustering',fontsize='large',fontweight='bold')\n",
        "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
        "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
        "plt.yticks(fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILj0LRWA5V0V"
      },
      "source": [
        "data1.groupby('clusterid_Kmeans').agg(['mean']).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jZn3PPp5eyi"
      },
      "source": [
        "**DBSCAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFVyJoNg5alK"
      },
      "source": [
        "from sklearn.cluster import DBSCAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz0czmJk5mQs"
      },
      "source": [
        "# Normalizing data using MinMaxScaler\n",
        "scaler1_df = scaler1.fit_transform(data1)\n",
        "print(scaler1_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_8gq9sG5wq8"
      },
      "source": [
        "**We will try for different values of eps and mn_samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4eYhvmp5pxX"
      },
      "source": [
        "# Using data normalized by MinMaxScaler\n",
        "dbscan = DBSCAN(eps=1, min_samples=12)\n",
        "dbscan.fit(scaler1_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjs9VMhV5ru6"
      },
      "source": [
        "#Noisy samples are given the label -1.\n",
        "dbscan.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq_3dxiR5rs6"
      },
      "source": [
        "y=pd.DataFrame(dbscan.fit_predict(scaler1_df),columns=['clusterid_DBSCAN'])\n",
        "y['clusterid_DBSCAN'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhxZYIqg5rqM"
      },
      "source": [
        "# silhouette score\n",
        "sil_score= silhouette_score(scaler1_df, dbscan.labels_)\n",
        "sil_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYIfHl3v5rls"
      },
      "source": [
        "# Plotting barplot using groupby method to get visualization of how many row no. in each cluster\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "data.groupby(['clusterid_DBSCAN']).count()['ID'].plot(kind='bar')\n",
        "plt.ylabel('ID Counts')\n",
        "plt.title('Hierarchical Clustering',fontsize='large',fontweight='bold')\n",
        "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
        "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
        "plt.yticks(fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1wkU0GH5rE0"
      },
      "source": [
        "# for epsilon = 0.8\n",
        "dbscan1 = DBSCAN(eps=0.8, min_samples=12)\n",
        "dbscan1.fit(scaler1_df)\n",
        "\n",
        "y=pd.DataFrame(dbscan1.fit_predict(scaler1_df),columns=['clusterid_DBSCAN'])\n",
        "print(y['clusterid_DBSCAN'].value_counts())\n",
        "\n",
        "# silhouette score\n",
        "sil_score= silhouette_score(scaler1_df, dbscan1.labels_)\n",
        "print('silhouette score: ',sil_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNoVxPzY770_"
      },
      "source": [
        "# for epsilon = 0.6\n",
        "dbscan2 = DBSCAN(eps=0.6, min_samples=12)\n",
        "dbscan2.fit(scaler1_df)\n",
        "\n",
        "y=pd.DataFrame(dbscan2.fit_predict(scaler1_df),columns=['clusterid_DBSCAN'])\n",
        "print(y['clusterid_DBSCAN'].value_counts())\n",
        "\n",
        "# silhouette score\n",
        "sil_score= silhouette_score(scaler1_df, dbscan2.labels_)\n",
        "print('silhouette score: ',sil_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iLUwweI8CPz"
      },
      "source": [
        "# for epsilon = 0.5\n",
        "dbscan3 = DBSCAN(eps=0.5, min_samples=12)\n",
        "dbscan3.fit(scaler1_df)\n",
        "\n",
        "y=pd.DataFrame(dbscan3.fit_predict(scaler1_df),columns=['clusterid_DBSCAN'])\n",
        "print(y['clusterid_DBSCAN'].value_counts())\n",
        "\n",
        "# silhouette score\n",
        "sil_score= silhouette_score(scaler1_df, dbscan3.labels_)\n",
        "print('silhouette score: ',sil_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRhS0b_A8G2y"
      },
      "source": [
        "# for epsilon = 0.55\n",
        "dbscan4 = DBSCAN(eps=0.55, min_samples=12)\n",
        "dbscan4.fit(scaler1_df)\n",
        "\n",
        "y=pd.DataFrame(dbscan4.fit_predict(scaler1_df),columns=['clusterid_DBSCAN'])\n",
        "print(y['clusterid_DBSCAN'].value_counts())\n",
        "\n",
        "# silhouette score\n",
        "sil_score= silhouette_score(scaler1_df, dbscan4.labels_)\n",
        "print('silhouette score: ',sil_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk4a2_a38Tdc"
      },
      "source": [
        "**When we have value of epsilon = 0.55, we are getting 6 clusters with data less than 50% in one cluster and also, silhouette score is more as compared to other dbscan models.**\n",
        "**-1 shows the noisy data points**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQhDQahx8NSg"
      },
      "source": [
        "data['clusterid_DBSCAN'] = dbscan4.labels_\n",
        "data1['clusterid_DBSCAN'] = dbscan4.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpGtzcmL8kMp"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCcSBXG58oRF"
      },
      "source": [
        "# Plotting barplot using groupby method to get visualization of how many row no. in each cluster\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "data.groupby(['clusterid_DBSCAN']).count()['ID'].plot(kind='bar')\n",
        "plt.ylabel('ID Counts')\n",
        "plt.title('Hierarchical Clustering',fontsize='large',fontweight='bold')\n",
        "ax.set_xlabel('Clusters', fontsize='large', fontweight='bold')\n",
        "ax.set_ylabel('ID counts', fontsize='large', fontweight='bold')\n",
        "plt.yticks(fontsize=15)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XLTGTjP8sBT"
      },
      "source": [
        "data1.groupby('clusterid_DBSCAN').agg(['mean']).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}