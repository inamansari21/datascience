{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inamansari21/datascience/blob/main/Forecasting_assng__2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2shAtqcyKTOI"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIoqHGaPKTOL"
      },
      "outputs": [],
      "source": [
        "# Loading Dataset\n",
        "data = pd.read_excel('Airlines+Data.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXnOEJASKTOM"
      },
      "source": [
        "### Visualization and Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BJ9tDyvKKTON"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4c4HILZ5KTOP"
      },
      "outputs": [],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "h2PORT5JKTOS"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g_cpxmiIKTOU"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "s5REnOJ1KTOW"
      },
      "outputs": [],
      "source": [
        "data.set_index('Month', inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DnOeolDJKTOX"
      },
      "outputs": [],
      "source": [
        "# Lineplot for Passengers\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Number of air passengers\")\n",
        "ax = plt.axes()\n",
        "ax.set_facecolor(\"black\")\n",
        "plt.plot(data['Passengers'], color = 'red', linewidth=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_YIeJCMtKTOY"
      },
      "outputs": [],
      "source": [
        "# Histogram\n",
        "ax = plt.axes()\n",
        "ax.set_facecolor(\"black\")\n",
        "data['Passengers'].hist(figsize=(8,5), color = 'red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lMljPsclKTOZ"
      },
      "outputs": [],
      "source": [
        "# Density Plot\n",
        "ax = plt.axes()\n",
        "ax.set_facecolor(\"black\")\n",
        "data['Passengers'].plot(kind = 'kde', figsize=(8,5), color = 'red')"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "NSoFf_ukKTOa"
      },
      "source": [
        "Passengers data is somewhat normally distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "W9pDUh1_KTOb"
      },
      "outputs": [],
      "source": [
        "# Lagplot\n",
        "from pandas.plotting import lag_plot\n",
        "\n",
        "lag_plot(data['Passengers'])\n",
        "ax = plt.axes()\n",
        "ax.set_facecolor(\"black\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "a9TvDPZsKTOc"
      },
      "outputs": [],
      "source": [
        "import statsmodels.graphics.tsaplots as tsa_plots\n",
        "tsa_plots.plot_acf(data.Passengers,lags=12)\n",
        "ax = plt.axes()\n",
        "ax.set_facecolor(\"black\")\n",
        "tsa_plots.plot_pacf(data.Passengers,lags=12)\n",
        "ax = plt.axes()\n",
        "ax.set_facecolor(\"black\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxNHc0TVKTOd"
      },
      "source": [
        "## Data Driven Forecasting Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9C3qeHMKTOd"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing # SES\n",
        "from statsmodels.tsa.holtwinters import Holt # Holts Exponential Smoothing\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPob5tnwKTOe"
      },
      "source": [
        "#### Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8E6Dqe9KTOe"
      },
      "outputs": [],
      "source": [
        "# Splitting data into Train and Test (77/33)\n",
        "Train = data.head(84)\n",
        "Test = data.tail(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "garaya1QKTOf"
      },
      "source": [
        "#### Moving Average Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "160vaz4jKTOf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "data.Passengers.plot(label=\"org\")\n",
        "for i in range(2,8,2):\n",
        "    data[\"Passengers\"].rolling(i).mean().plot(label=str(i))\n",
        "plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "msecgBBcKTOg"
      },
      "source": [
        "With windows = 2, we are getting less deviation of the forecasting values with original values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLa5R8JKKTOg"
      },
      "source": [
        "#### Time series decomposition plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rRS73JxNKTOh"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "decompose_ts_add = seasonal_decompose(data.Passengers)\n",
        "decompose_ts_add.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_cU1ADDKTOi"
      },
      "source": [
        "#### Evaluation Metric RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzbwhtsQKTOj"
      },
      "outputs": [],
      "source": [
        "def RMSE(org, pred):\n",
        "    rmse=np.sqrt(np.mean((np.array(org)-np.array(pred))**2))\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWlzEzhfKTOj"
      },
      "source": [
        "#### Simple Exponential Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh9ZtqAoKTOk"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_PBtNlWUKTOk"
      },
      "outputs": [],
      "source": [
        "ses_model = SimpleExpSmoothing(Train[\"Passengers\"]).fit()\n",
        "pred_ses = ses_model.predict(start = Test.index[0],end = Test.index[-1])\n",
        "rmse_ses_model = RMSE(Test.Passengers, pred_ses)\n",
        "rmse_ses_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3moVKhTWKTOl"
      },
      "source": [
        "#### Holt method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz_CRS6BKTOl"
      },
      "outputs": [],
      "source": [
        "hw_model = Holt(Train[\"Passengers\"]).fit()\n",
        "pred_hw = hw_model.predict(start = Test.index[0],end = Test.index[-1])\n",
        "rmse_hw_model = RMSE(Test.Passengers, pred_hw)\n",
        "rmse_hw_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2OZkF63KTOl"
      },
      "source": [
        "#### Holts winter exponential smoothing with additive seasonality and additive trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKx-ULOhKTOm"
      },
      "outputs": [],
      "source": [
        "hwe_model_add_add = ExponentialSmoothing(Train[\"Passengers\"],seasonal=\"add\",trend=\"add\",seasonal_periods=4).fit()\n",
        "pred_hwe_add_add = hwe_model_add_add.predict(start = Test.index[0],end = Test.index[-1])\n",
        "rmse_hwe_add_add_model = RMSE(Test.Passengers, pred_hwe_add_add)\n",
        "rmse_hwe_add_add_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRAHresLKTOm"
      },
      "source": [
        "#### Holts winter exponential smoothing with multiplicative seasonality and additive trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl3dQ_BkKTOn"
      },
      "outputs": [],
      "source": [
        "hwe_model_mul_add = ExponentialSmoothing(Train[\"Passengers\"],seasonal=\"mul\",trend=\"add\",seasonal_periods=4).fit() \n",
        "pred_hwe_mul_add = hwe_model_mul_add.predict(start = Test.index[0],end = Test.index[-1])\n",
        "rmse_hwe_model_mul_add_model = RMSE(Test.Passengers, pred_hwe_mul_add)\n",
        "rmse_hwe_model_mul_add_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blrw4OigKTOn"
      },
      "source": [
        "## Model based Forecasting Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "o8JBMomuKTOo"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing for models\n",
        "data1 = data.copy()\n",
        "data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_4TqTz9KTOo"
      },
      "outputs": [],
      "source": [
        "data1[\"t\"] = np.arange(1,97)\n",
        "data1[\"t_squared\"] = data1[\"t\"]*data1[\"t\"]\n",
        "\n",
        "data1[\"log_psngr\"] = np.log(data1[\"Passengers\"])\n",
        "\n",
        "data1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lt4BezqKTOo"
      },
      "source": [
        "#### Splitting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF5tKM6QKTOp"
      },
      "outputs": [],
      "source": [
        "# Splitting data into Train and Test (77/33)\n",
        "Train = data1.head(84)\n",
        "Test = data1.tail(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb-q2MJtKTOp"
      },
      "source": [
        "#### Linear Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHin4aa6KTOp"
      },
      "outputs": [],
      "source": [
        "import statsmodels.formula.api as smf \n",
        "\n",
        "linear_model = smf.ols('Passengers~t',data=Train).fit()\n",
        "pred_linear =  pd.Series(linear_model.predict(pd.DataFrame(Test['t'])))\n",
        "rmse_linear_model = RMSE(Test['Passengers'], pred_linear)\n",
        "rmse_linear_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYb-oh4vKTOq"
      },
      "source": [
        "#### Exponential Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE97T3QZKTOq"
      },
      "outputs": [],
      "source": [
        "Exp = smf.ols('log_psngr~t',data=Train).fit()\n",
        "pred_Exp = pd.Series(Exp.predict(pd.DataFrame(Test['t'])))\n",
        "rmse_Exp_model = RMSE(Test['Passengers'], np.exp(pred_Exp))\n",
        "rmse_Exp_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOCJqVdBKTOq"
      },
      "source": [
        "#### Quadratic Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cNiZ_q4KTOr"
      },
      "outputs": [],
      "source": [
        "Quad = smf.ols('Passengers~t+t_squared',data=Train).fit()\n",
        "pred_Quad = pd.Series(Quad.predict(Test[[\"t\",\"t_squared\"]]))\n",
        "rmse_Quad_model = RMSE(Test['Passengers'], pred_Quad)\n",
        "rmse_Quad_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-Kr0HWTKTOr"
      },
      "source": [
        "#### ARIMA model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP5pja9_KTOr"
      },
      "outputs": [],
      "source": [
        "series = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6ov6lnoKTOr"
      },
      "outputs": [],
      "source": [
        "series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FvdHuXfKTOs"
      },
      "outputs": [],
      "source": [
        "# separate out a validation dataset\n",
        "split_point = len(series) - 12\n",
        "dataset, validation = series[0:split_point], series[split_point:]\n",
        "print('Dataset %d, Validation %d' % (len(dataset), len(validation)))\n",
        "dataset.to_csv('dataset.csv', header=False)\n",
        "validation.to_csv('validation.csv', header=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhBVdSkHKTOt"
      },
      "source": [
        "#### Persistence/ Base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgbL_pMFKTOt"
      },
      "outputs": [],
      "source": [
        "# evaluate a persistence model\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "# load data\n",
        "train = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "# prepare data\n",
        "X = train.values\n",
        "X = X.astype('float32')\n",
        "train_size = int(len(X) * 0.715)\n",
        "train, test = X[0:train_size], X[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXhhD7u7KTOu"
      },
      "outputs": [],
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Cu_q_c8bKTOu"
      },
      "outputs": [],
      "source": [
        "# walk-forward validation\n",
        "history = [x for x in train]\n",
        "predictions = list()\n",
        "for i in range(len(test)):\n",
        "    yhat = history[-1]\n",
        "    predictions.append(yhat)\n",
        "# observation\n",
        "    obs = test[i]\n",
        "    history.append(obs)\n",
        "    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n",
        "# report performance\n",
        "rmse = sqrt(mean_squared_error(test, predictions))\n",
        "print('RMSE: %.3f' % rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57QiGgbrKTOv"
      },
      "outputs": [],
      "source": [
        "rmse_Persistence_model = 29.058 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoojwUKfKTOv"
      },
      "source": [
        "### ARIMA Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0mgbp0VKTOw"
      },
      "outputs": [],
      "source": [
        "series = pd.read_excel('Airlines+Data.xlsx', header=0, index_col=0, parse_dates=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "X0TYY_M6KTOw"
      },
      "outputs": [],
      "source": [
        "series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSayVJ7iKTOw"
      },
      "outputs": [],
      "source": [
        "# separate out a validation dataset\n",
        "split_point = len(series) - 12\n",
        "dataset, validation = series[0:split_point], series[split_point:]\n",
        "print('Dataset %d, Validation %d' % (len(dataset), len(validation)))\n",
        "dataset.to_csv('dataset.csv', header=False)\n",
        "validation.to_csv('validation.csv', header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PW5M9FJGKTOx"
      },
      "outputs": [],
      "source": [
        "# grid search ARIMA parameters for a time series\n",
        "\n",
        "import warnings\n",
        "from pandas import read_csv\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\n",
        "def evaluate_arima_model(X, arima_order):\n",
        "# prepare training dataset\n",
        "    X = X.astype('float32')\n",
        "    train_size = int(len(X) * 0.715)\n",
        "    train, test = X[0:train_size], X[train_size:]\n",
        "    history = [x for x in train]\n",
        "# make predictions\n",
        "    predictions = list()\n",
        "    for t in range(len(test)):\n",
        "        model = ARIMA(history, order=arima_order)\n",
        "# model_fit = model.fit(disp=0)\n",
        "        model_fit = model.fit(disp=0)\n",
        "        yhat = model_fit.forecast()[0]\n",
        "        predictions.append(yhat)\n",
        "        history.append(test[t])\n",
        "# calculate out of sample error\n",
        "    rmse = sqrt(mean_squared_error(test, predictions))\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOeuDavZKTOx"
      },
      "outputs": [],
      "source": [
        "# evaluate combinations of p, d and q values for an ARIMA model\n",
        "def evaluate_models(dataset, p_values, d_values, q_values):\n",
        "    dataset = dataset.astype('float32')\n",
        "    best_score, best_cfg = float('inf'), None\n",
        "    for p in p_values:\n",
        "        for d in d_values:\n",
        "            for q in q_values:\n",
        "                order = (p,d,q)\n",
        "                try:\n",
        "                    rmse = evaluate_arima_model(train, order)\n",
        "                    if rmse < best_score:\n",
        "                        best_score, best_cfg = rmse, order\n",
        "                    print('ARIMA%s RMSE=%.3f' % (order,rmse))\n",
        "                except:\n",
        "                    continue\n",
        "    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MyqzA4jzKTOy"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "train = pd.read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\n",
        "# evaluate parameters\n",
        "p_values = range(0, 5)\n",
        "d_values = range(0, 5)\n",
        "q_values = range(0, 5)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "evaluate_models(train.values, p_values, d_values, q_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "55D_EUH9KTOz"
      },
      "outputs": [],
      "source": [
        "rmse_ARIMA_model = 24.650"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD5lY8kpKTOz"
      },
      "source": [
        "#### Build Model based on the optimized values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMok7urAKTO0"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "train = pd.read_csv('dataset.csv', header=0, index_col=0, parse_dates=True)\n",
        "# prepare data\n",
        "X = train.values\n",
        "X = X.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XTDurzIyKTO0"
      },
      "outputs": [],
      "source": [
        "# fit model\n",
        "model = ARIMA(X, order=(3,1,0))\n",
        "model_fit = model.fit()\n",
        "forecast=model_fit.forecast(steps=12)[0]\n",
        "model_fit.plot_predict(1, 96)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HMKSgUVNKTO1"
      },
      "outputs": [],
      "source": [
        "#Error on the test data\n",
        "val=pd.read_csv('validation.csv',header=None)\n",
        "rmse = sqrt(mean_squared_error(val[1], forecast))\n",
        "rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE1nvdMOKTO1"
      },
      "source": [
        "#### Combine train and test data and build final model¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIYydMhdKTO1"
      },
      "outputs": [],
      "source": [
        "# fit model\n",
        "data = pd.read_excel('Airlines+Data.xlsx', header=0, index_col=0, parse_dates=True)\n",
        "# prepare data\n",
        "X = train.values\n",
        "X = X.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_m_Ti8zKTO2"
      },
      "outputs": [],
      "source": [
        "model = ARIMA(X, order=(0,1,4))\n",
        "model_fit = model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "XxWAnN3SKTO2"
      },
      "outputs": [],
      "source": [
        "forecast=model_fit.forecast(steps=12)[0]\n",
        "model_fit.plot_predict(1,97)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "P0Vz4h7fKTO2"
      },
      "outputs": [],
      "source": [
        "forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnIAWUgpKTO3"
      },
      "outputs": [],
      "source": [
        "list = [['Simple Exponential Method',rmse_ses_model], ['Holt method',rmse_hw_model],\n",
        "          ['HW exp smoothing add',rmse_hwe_add_add_model],['HW exp smoothing mult',rmse_hwe_model_mul_add_model],\n",
        "          ['Linear Mode',rmse_linear_model],['Exp model',rmse_Exp_model],['Quad model',rmse_Quad_model],\n",
        "          ['Persistence/ Base model', rmse_Persistence_model], ['ARIMA Model', rmse_ARIMA_model]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6-6aYa4KTO3"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(list, columns =['Model', 'RMSE_Value']) \n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IRJpuwm1L06S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Forecasting_assng_ 2 .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}