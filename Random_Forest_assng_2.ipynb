{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inamansari21/datascience/blob/main/Random_Forest_assng_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "f_E9O8t89PYi"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "# Read in data and display first 5 rows\n",
        "features = pd.read_csv('Company_Data.csv')\n",
        "features.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "kPh0nn149PYk"
      },
      "cell_type": "code",
      "source": [
        "#getting information of dataset\n",
        "features.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IUSrg8UE9PYk"
      },
      "cell_type": "code",
      "source": [
        "print('The shape of our features is:', features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7X5iFPi19PYl"
      },
      "cell_type": "code",
      "source": [
        "features.isnull().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "W5YgrzN89PYm"
      },
      "cell_type": "code",
      "source": [
        "# let's plot pair plot to visualise the attributes all at once\n",
        "sns.pairplot(data=features, hue = 'ShelveLoc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "DE9_HpD09PYo"
      },
      "cell_type": "code",
      "source": [
        "#Creating dummy vairables dropping first dummy variable\n",
        "df=pd.get_dummies(features,columns=['Urban','US'], drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "HqHYS4fj9PYp"
      },
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yXW74NlQ9PYp"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-2b9kk349PYq"
      },
      "cell_type": "code",
      "source": [
        "df['ShelveLoc']=df['ShelveLoc'].map({'Good':1,'Medium':2,'Bad':3})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "gUoxwUPy9PYr"
      },
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_sXXlDQE9PYr"
      },
      "cell_type": "code",
      "source": [
        "x=df.iloc[:,0:6]\n",
        "y=df['ShelveLoc']\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aaskzVaV9PYs"
      },
      "cell_type": "code",
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "XrfayuuP9PYt"
      },
      "cell_type": "code",
      "source": [
        "df['ShelveLoc'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WJuO3B039PYu"
      },
      "cell_type": "code",
      "source": [
        "df.ShelveLoc.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "kJj0VsGB9PYv"
      },
      "cell_type": "code",
      "source": [
        "colnames = list(df.columns)\n",
        "colnames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pLLmmsFp9PYw"
      },
      "cell_type": "code",
      "source": [
        "# Descriptive statistics for each column\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Pzy3CKH_9PYw"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "jyV27-rQ9PYx"
      },
      "cell_type": "code",
      "source": [
        "# Labels are the values we want to predict\n",
        "labels = np.array(df['Income'])\n",
        "# Remove the labels from the features\n",
        "# axis 1 refers to the columns\n",
        "features= df.drop('Income', axis = 1)\n",
        "# Saving feature names for later use\n",
        "feature_list = list(df.columns)\n",
        "# Convert to numpy array\n",
        "features = np.array(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "BX5ik6tz9PYx"
      },
      "cell_type": "code",
      "source": [
        "# Using Skicit-learn to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "jz9kyTa59PYx"
      },
      "cell_type": "code",
      "source": [
        "print('Training Features Shape:', train_features.shape)\n",
        "print('Training Labels Shape:', train_labels.shape)\n",
        "print('Testing Features Shape:', test_features.shape)\n",
        "print('Testing Labels Shape:', test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uvfR2ZjX9PYy"
      },
      "cell_type": "markdown",
      "source": [
        "# Establish Baseline"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uQ2sfkdu9PYy"
      },
      "cell_type": "code",
      "source": [
        "# The baseline predictions are the historical averages\n",
        "baseline_preds = test_features[:, feature_list.index('Sales')]\n",
        "# Baseline errors, and display average baseline error\n",
        "baseline_errors = abs(baseline_preds - test_labels)\n",
        "print('Average baseline error: ', round(np.mean(baseline_errors), 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RJ7YG6QL9PYz"
      },
      "cell_type": "code",
      "source": [
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
        "# Train the model on training data\n",
        "rf.fit(train_features, train_labels);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8HlIAsGq9PYz"
      },
      "cell_type": "code",
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(test_features)\n",
        "# Calculate the absolute errors\n",
        "errors = abs(predictions - test_labels)\n",
        "# Print out the mean absolute error (mae)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "web-JhMD9PYz"
      },
      "cell_type": "markdown",
      "source": [
        "Determine Performance Metrics"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "18K1Cere9PYz"
      },
      "cell_type": "code",
      "source": [
        "# Calculate mean absolute percentage error (MAPE)\n",
        "mape = 100 * (errors / test_labels)\n",
        "# Calculate and display accuracy\n",
        "accuracy = 100 - np.mean(mape)\n",
        "print('Accuracy:', round(accuracy, 2), '%.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "UVn09AhE9PY0"
      },
      "cell_type": "code",
      "source": [
        "# Import tools needed for visualization\n",
        "from sklearn.tree import export_graphviz\n",
        "import pydot\n",
        "# Pull out one tree from the forest\n",
        "tree = rf.estimators_[5]\n",
        "# Import tools needed for visualization\n",
        "from sklearn.tree import export_graphviz\n",
        "import pydot\n",
        "# Pull out one tree from the forest\n",
        "tree = rf.estimators_[5]\n",
        "# Export the image to a dot file\n",
        "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
        "# Use dot file to create a graph\n",
        "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
        "# Write graph to a png file\n",
        "graph.write_png('tree.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Sf5p4lw39PY0"
      },
      "cell_type": "code",
      "source": [
        "# Limit depth of tree to 3 levels\n",
        "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\n",
        "rf_small.fit(train_features, train_labels)\n",
        "# Extract the small tree\n",
        "tree_small = rf_small.estimators_[5]\n",
        "# Save the tree as a png image\n",
        "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
        "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
        "graph.write_png('small_tree.png');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8ECArZ-59PY0"
      },
      "cell_type": "code",
      "source": [
        "# Get numerical feature importances\n",
        "importances = list(rf.feature_importances_)\n",
        "# List of tuples with variable and importance\n",
        "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
        "# Sort the feature importances by most important first\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "# Print out the feature and importances \n",
        "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "boR-H2Ts9PY1"
      },
      "cell_type": "code",
      "source": [
        "# New random forest with only the two most important variables\n",
        "rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
        "# Extract the two most important features\n",
        "important_indices = [feature_list.index('Sales'), feature_list.index('Income')]\n",
        "train_important = train_features[:, important_indices]\n",
        "test_important = test_features[:, important_indices]\n",
        "# Train the random forest\n",
        "rf_most_important.fit(train_important, train_labels)\n",
        "# Make predictions and determine the error\n",
        "predictions = rf_most_important.predict(test_important)\n",
        "errors = abs(predictions - test_labels)\n",
        "# Display the performance metrics\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
        "mape = np.mean(100 * (errors / test_labels))\n",
        "accuracy = 100 - mape\n",
        "print('Accuracy:', round(accuracy, 2), '%.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YrruiB_r9PY1"
      },
      "cell_type": "code",
      "source": [
        "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Set the style\n",
        "plt.style.use('fivethirtyeight')\n",
        "# list of x locations for plotting\n",
        "x_values = list(range(len(importances)))\n",
        "# Make a bar chart\n",
        "plt.bar(x_values, importances, orientation = 'vertical')\n",
        "# Tick labels for x axis\n",
        "plt.xticks(x_values, feature_list, rotation='vertical')\n",
        "# Axis labels and title\n",
        "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h922bTwk-b4h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "gist": {
      "id": "2cf79d3dacb6c4da725db40bdd53b0e6",
      "data": {
        "description": "Assignment 15- Random Forest.ipynb",
        "public": true
      }
    },
    "_draft": {
      "nbviewer_url": "https://gist.github.com/2cf79d3dacb6c4da725db40bdd53b0e6"
    },
    "colab": {
      "name": "Random Forest_assng_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}