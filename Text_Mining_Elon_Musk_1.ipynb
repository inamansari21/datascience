{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inamansari21/datascience/blob/main/Text_Mining_Elon_Musk_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eac76c71",
      "metadata": {
        "id": "eac76c71"
      },
      "source": [
        "# 1) Perform sentimental analysis on the Elon-musk tweets (Exlon-musk.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "745a3887",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:23.715446Z",
          "start_time": "2021-09-14T19:28:23.707404Z"
        },
        "id": "745a3887"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import spacy\n",
        "\n",
        "from matplotlib.pyplot import imread\n",
        "from wordcloud import WordCloud, STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c1fc45c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:28.073160Z",
          "start_time": "2021-09-14T19:28:28.017087Z"
        },
        "id": "2c1fc45c"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "tweets=pd.read_csv('Elon_musk.csv',encoding='Latin-1')\n",
        "tweets.drop(['Unnamed: 0'],inplace=True,axis=1)\n",
        "tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b79cb4a",
      "metadata": {
        "id": "5b79cb4a"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aae0dcb4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:32.212922Z",
          "start_time": "2021-09-14T19:28:32.188842Z"
        },
        "id": "aae0dcb4"
      },
      "outputs": [],
      "source": [
        "tweets=[Text.strip() for Text in tweets.Text] # remove both the leading and the trailing characters\n",
        "tweets=[Text for Text in tweets if Text] # removes empty strings, because they are considered in Python as False\n",
        "tweets[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee561f0f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:34.850032Z",
          "start_time": "2021-09-14T19:28:34.826039Z"
        },
        "id": "ee561f0f"
      },
      "outputs": [],
      "source": [
        "# Joining the list into one string/text\n",
        "tweets_text=' '.join(tweets)\n",
        "tweets_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7051499",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:38.403093Z",
          "start_time": "2021-09-14T19:28:38.296687Z"
        },
        "id": "f7051499"
      },
      "outputs": [],
      "source": [
        "# remove Twitter username handles from a given twitter text. (Removes @usernames)\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer(strip_handles=True)\n",
        "tweets_tokens=tknzr.tokenize(tweets_text)\n",
        "print(tweets_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e2bc22",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:41.157532Z",
          "start_time": "2021-09-14T19:28:41.133540Z"
        },
        "id": "14e2bc22"
      },
      "outputs": [],
      "source": [
        "# Again Joining the list into one string/text\n",
        "tweets_tokens_text=' '.join(tweets_tokens)\n",
        "tweets_tokens_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "831c1690",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:44.246808Z",
          "start_time": "2021-09-14T19:28:44.206693Z"
        },
        "id": "831c1690"
      },
      "outputs": [],
      "source": [
        "# Remove Punctuations \n",
        "no_punc_text=tweets_tokens_text.translate(str.maketrans('','',string.punctuation))\n",
        "no_punc_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f57999",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:47.402653Z",
          "start_time": "2021-09-14T19:28:47.386646Z"
        },
        "id": "d9f57999"
      },
      "outputs": [],
      "source": [
        "# remove https or url within text\n",
        "import re\n",
        "no_url_text=re.sub(r'http\\S+', '', no_punc_text)\n",
        "no_url_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99461201",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:50.890424Z",
          "start_time": "2021-09-14T19:28:50.874428Z"
        },
        "id": "99461201"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a220c05",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:53.728768Z",
          "start_time": "2021-09-14T19:28:53.656715Z"
        },
        "id": "3a220c05"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text_tokens=word_tokenize(no_url_text)\n",
        "print(text_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12fee083",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:28:58.057782Z",
          "start_time": "2021-09-14T19:28:58.041787Z"
        },
        "id": "12fee083"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e15f7fb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:29:00.940454Z",
          "start_time": "2021-09-14T19:29:00.924456Z"
        },
        "id": "9e15f7fb"
      },
      "outputs": [],
      "source": [
        "# Tokens count\n",
        "len(text_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6d9f06",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:29:04.712080Z",
          "start_time": "2021-09-14T19:29:04.664002Z"
        },
        "id": "fb6d9f06"
      },
      "outputs": [],
      "source": [
        "# Remove Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "my_stop_words=stopwords.words('english')\n",
        "\n",
        "sw_list = ['\\x92','rt','ye','yeah','haha','Yes','U0001F923','I']\n",
        "my_stop_words.extend(sw_list)\n",
        "\n",
        "no_stop_tokens=[word for word in text_tokens if not word in my_stop_words]\n",
        "print(no_stop_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f671294",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:29:07.676450Z",
          "start_time": "2021-09-14T19:29:07.660453Z"
        },
        "id": "7f671294"
      },
      "outputs": [],
      "source": [
        "# Normalize the data\n",
        "lower_words=[Text.lower() for Text in no_stop_tokens]\n",
        "print(lower_words[100:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ec5396",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:29:10.437023Z",
          "start_time": "2021-09-14T19:29:10.241377Z"
        },
        "id": "23ec5396"
      },
      "outputs": [],
      "source": [
        "# Stemming (Optional)\n",
        "from nltk.stem import PorterStemmer\n",
        "ps=PorterStemmer()\n",
        "stemmed_tokens=[ps.stem(word) for word in lower_words]\n",
        "print(stemmed_tokens[100:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "770e0770",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:42:10.457144Z",
          "start_time": "2021-09-14T19:42:04.056662Z"
        },
        "id": "770e0770"
      },
      "outputs": [],
      "source": [
        "!pip3 install en_core_web_sm\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "259ba354",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:42:21.485856Z",
          "start_time": "2021-09-14T19:42:19.164430Z"
        },
        "id": "259ba354"
      },
      "outputs": [],
      "source": [
        "# Lemmatization\n",
        "import spacy\n",
        "from spacy.lang.en.examples import sentences\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "doc=nlp(' '.join(lower_words))\n",
        "print(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c32423",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:42:45.511349Z",
          "start_time": "2021-09-14T19:42:45.487285Z"
        },
        "id": "f7c32423"
      },
      "outputs": [],
      "source": [
        "lemmas=[token.lemma_ for token in doc]\n",
        "print(lemmas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c811882",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:43:13.274138Z",
          "start_time": "2021-09-14T19:43:13.258075Z"
        },
        "id": "2c811882"
      },
      "outputs": [],
      "source": [
        "clean_tweets=' '.join(lemmas)\n",
        "clean_tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86cd891",
      "metadata": {
        "id": "e86cd891"
      },
      "source": [
        "# Feature Extaction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efed81b9",
      "metadata": {
        "id": "efed81b9"
      },
      "source": [
        "# 1. Using CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740069fe",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:44:11.059469Z",
          "start_time": "2021-09-14T19:44:10.995495Z"
        },
        "id": "740069fe"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "tweetscv=cv.fit_transform(lemmas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d1a9325",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:44:18.315660Z",
          "start_time": "2021-09-14T19:44:18.299580Z"
        },
        "id": "4d1a9325"
      },
      "outputs": [],
      "source": [
        "print(cv.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e9de696",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:44:47.819613Z",
          "start_time": "2021-09-14T19:44:47.795546Z"
        },
        "id": "6e9de696"
      },
      "outputs": [],
      "source": [
        "print(cv.get_feature_names()[100:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d032ced7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:44:54.231034Z",
          "start_time": "2021-09-14T19:44:54.197543Z"
        },
        "id": "d032ced7"
      },
      "outputs": [],
      "source": [
        "print(tweetscv.toarray()[100:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6c16cae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:45:01.834954Z",
          "start_time": "2021-09-14T19:45:01.794894Z"
        },
        "id": "a6c16cae"
      },
      "outputs": [],
      "source": [
        "print(tweetscv.toarray().shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef180a90",
      "metadata": {
        "id": "ef180a90"
      },
      "source": [
        "# 2. CountVectorizer with N-grams (Bigrams & Trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a68860e0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:45:35.457519Z",
          "start_time": "2021-09-14T19:45:35.385482Z"
        },
        "id": "a68860e0"
      },
      "outputs": [],
      "source": [
        "cv_ngram_range=CountVectorizer(analyzer='word',ngram_range=(1,3),max_features=100)\n",
        "bow_matrix_ngram=cv_ngram_range.fit_transform(lemmas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7eec799",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:45:58.220802Z",
          "start_time": "2021-09-14T19:45:58.196765Z"
        },
        "id": "f7eec799"
      },
      "outputs": [],
      "source": [
        "print(cv_ngram_range.get_feature_names())\n",
        "print(bow_matrix_ngram.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04d9d7a4",
      "metadata": {
        "id": "04d9d7a4"
      },
      "source": [
        "# 3. TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a787f9c2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:46:39.030569Z",
          "start_time": "2021-09-14T19:46:38.950482Z"
        },
        "id": "a787f9c2"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfv_ngram_max_features=TfidfVectorizer(norm='l2',analyzer='word',ngram_range=(1,3),max_features=500)\n",
        "tfidf_matix_ngram=tfidfv_ngram_max_features.fit_transform(lemmas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99646adc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:46:45.889720Z",
          "start_time": "2021-09-14T19:46:45.857720Z"
        },
        "id": "99646adc"
      },
      "outputs": [],
      "source": [
        "print(tfidfv_ngram_max_features.get_feature_names())\n",
        "print(tfidf_matix_ngram.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf16abc",
      "metadata": {
        "id": "0bf16abc"
      },
      "source": [
        "# Generate Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e10caba",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:47:38.708667Z",
          "start_time": "2021-09-14T19:47:30.092782Z"
        },
        "id": "5e10caba"
      },
      "outputs": [],
      "source": [
        "# Define a function to plot word cloud\n",
        "def plot_cloud(wordcloud):\n",
        "    plt.figure(figsize=(40,30))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis('off')\n",
        "    \n",
        "# Generate Word Cloud\n",
        "\n",
        "STOPWORDS.add('pron')\n",
        "STOPWORDS.add('rt')\n",
        "STOPWORDS.add('yeah')\n",
        "wordcloud=WordCloud(width=3000,height=2000,background_color='black',max_words=50,\n",
        "                   colormap='Set1',stopwords=STOPWORDS).generate(clean_tweets)\n",
        "plot_cloud(wordcloud)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a162ba1a",
      "metadata": {
        "id": "a162ba1a"
      },
      "source": [
        "# Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d00bb799",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:48:01.771589Z",
          "start_time": "2021-09-14T19:47:59.546561Z"
        },
        "id": "d00bb799"
      },
      "outputs": [],
      "source": [
        "# Parts Of Speech (POS) Tagging\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "one_block=clean_tweets\n",
        "doc_block=nlp(one_block)\n",
        "spacy.displacy.render(doc_block,style='ent',jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d5593b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:48:20.433021Z",
          "start_time": "2021-09-14T19:48:20.409032Z"
        },
        "id": "76d5593b"
      },
      "outputs": [],
      "source": [
        "for token in doc_block[100:200]:\n",
        "    print(token,token.pos_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca396727",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:48:53.653456Z",
          "start_time": "2021-09-14T19:48:53.629385Z"
        },
        "id": "ca396727"
      },
      "outputs": [],
      "source": [
        "# Filtering the nouns and verbs only\n",
        "nouns_verbs=[token.text for token in doc_block if token.pos_ in ('NOUN','VERB')]\n",
        "print(nouns_verbs[100:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ef555f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:49:31.907261Z",
          "start_time": "2021-09-14T19:49:31.851283Z"
        },
        "id": "a9ef555f"
      },
      "outputs": [],
      "source": [
        "# Counting the noun & verb tokens\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "\n",
        "X=cv.fit_transform(nouns_verbs)\n",
        "sum_words=X.sum(axis=0)\n",
        "\n",
        "words_freq=[(word,sum_words[0,idx]) for word,idx in cv.vocabulary_.items()]\n",
        "words_freq=sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "wd_df=pd.DataFrame(words_freq)\n",
        "wd_df.columns=['word','count']\n",
        "wd_df[0:10] # viewing top ten results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9b9e2e7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:49:42.867835Z",
          "start_time": "2021-09-14T19:49:42.627995Z"
        },
        "id": "a9b9e2e7"
      },
      "outputs": [],
      "source": [
        "# Visualizing results (Barchart for top 10 nouns + verbs)\n",
        "wd_df[0:10].plot.bar(x='word',figsize=(12,8),title='Top 10 nouns and verbs');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa2e7c5e",
      "metadata": {
        "id": "aa2e7c5e"
      },
      "source": [
        "# Emotion Mining - Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53daab11",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:50:10.466325Z",
          "start_time": "2021-09-14T19:50:10.394224Z"
        },
        "id": "53daab11"
      },
      "outputs": [],
      "source": [
        "from nltk import tokenize\n",
        "sentences=tokenize.sent_tokenize(' '.join(tweets))\n",
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aebd3ec8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:50:47.663914Z",
          "start_time": "2021-09-14T19:50:47.647875Z"
        },
        "id": "aebd3ec8"
      },
      "outputs": [],
      "source": [
        "sent_df=pd.DataFrame(sentences,columns=['sentence'])\n",
        "sent_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c87ecd6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:54:23.463032Z",
          "start_time": "2021-09-14T19:54:23.423116Z"
        },
        "id": "5c87ecd6"
      },
      "outputs": [],
      "source": [
        "# Emotion Lexicon - Affin\n",
        "affin=pd.read_csv('Afinn.csv',sep=',',encoding='Latin-1')\n",
        "affin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52026e25",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:54:41.967476Z",
          "start_time": "2021-09-14T19:54:41.927388Z"
        },
        "id": "52026e25"
      },
      "outputs": [],
      "source": [
        "affinity_scores=affin.set_index('word')['value'].to_dict()\n",
        "affinity_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c6b6ba5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:55:05.274602Z",
          "start_time": "2021-09-14T19:55:04.940309Z"
        },
        "id": "1c6b6ba5"
      },
      "outputs": [],
      "source": [
        "# Custom function: score each word in a sentence in lemmatised form, but calculate the score for the whole original sentence\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "sentiment_lexicon=affinity_scores\n",
        "\n",
        "def calculate_sentiment(text:str=None):\n",
        "    sent_score=0\n",
        "    if text:\n",
        "        sentence=nlp(text)\n",
        "        for word in sentence:\n",
        "            sent_score+=sentiment_lexicon.get(word.lemma_,0)\n",
        "    return sent_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "684a7b4f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:55:11.613331Z",
          "start_time": "2021-09-14T19:55:11.589267Z"
        },
        "id": "684a7b4f"
      },
      "outputs": [],
      "source": [
        "# manual testing\n",
        "calculate_sentiment(text='great')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "156f53ca",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:55:25.735658Z",
          "start_time": "2021-09-14T19:55:18.127186Z"
        },
        "id": "156f53ca"
      },
      "outputs": [],
      "source": [
        "# Calculating sentiment value for each sentence\n",
        "sent_df['sentiment_value']=sent_df['sentence'].apply(calculate_sentiment)\n",
        "sent_df['sentiment_value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed74970",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:55:40.898985Z",
          "start_time": "2021-09-14T19:55:40.882962Z"
        },
        "id": "bed74970"
      },
      "outputs": [],
      "source": [
        "# how many words are there in a sentence?\n",
        "sent_df['word_count']=sent_df['sentence'].str.split().apply(len)\n",
        "sent_df['word_count']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9452bb8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:55:50.796605Z",
          "start_time": "2021-09-14T19:55:50.772612Z"
        },
        "id": "a9452bb8"
      },
      "outputs": [],
      "source": [
        "sent_df.sort_values(by='sentiment_value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05d2cae3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:55:58.936895Z",
          "start_time": "2021-09-14T19:55:58.912913Z"
        },
        "id": "05d2cae3"
      },
      "outputs": [],
      "source": [
        "# Sentiment score of the whole review\n",
        "sent_df['sentiment_value'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfcc515f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:56:07.894531Z",
          "start_time": "2021-09-14T19:56:04.812752Z"
        },
        "id": "cfcc515f"
      },
      "outputs": [],
      "source": [
        "# negative sentiment score of the whole review\n",
        "sent_df[sent_df['sentiment_value']<=0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7a06d1d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:56:12.393647Z",
          "start_time": "2021-09-14T19:56:12.369695Z"
        },
        "id": "c7a06d1d"
      },
      "outputs": [],
      "source": [
        "# positive sentiment score of the whole review\n",
        "sent_df[sent_df['sentiment_value']>0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e7619b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:56:33.604606Z",
          "start_time": "2021-09-14T19:56:33.580531Z"
        },
        "id": "f2e7619b"
      },
      "outputs": [],
      "source": [
        "# Adding index cloumn\n",
        "sent_df['index']=range(0,len(sent_df))\n",
        "sent_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "319c42d7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:56:41.686694Z",
          "start_time": "2021-09-14T19:56:40.249962Z"
        },
        "id": "319c42d7"
      },
      "outputs": [],
      "source": [
        "# Plotting the sentiment value for whole review\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.distplot(sent_df['sentiment_value'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "641460e6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:56:50.400093Z",
          "start_time": "2021-09-14T19:56:50.186269Z"
        },
        "id": "641460e6"
      },
      "outputs": [],
      "source": [
        "# Plotting the line plot for sentiment value of whole review\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.lineplot(y='sentiment_value',x='index',data=sent_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53497761",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-14T19:57:00.135833Z",
          "start_time": "2021-09-14T19:56:59.970951Z"
        },
        "id": "53497761"
      },
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "sent_df.plot.scatter(x='word_count',y='sentiment_value',figsize=(8,8),title='Sentence sentiment value to sentence word count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c11bfb3",
      "metadata": {
        "id": "0c11bfb3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "_ Text-Mining_Elon_Musk 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}